{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3382cf2-8cbb-48c6-ba22-828edc3e66ab",
   "metadata": {},
   "source": [
    "# Information Extraction\n",
    "\n",
    "1. Load and split\n",
    "2. Vectorsearch (retrieval)\n",
    "\n",
    "TODO:\n",
    "* paper for extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "945d388b-5dfb-4de5-b180-aa4bd8d8aa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://127.0.0.1:6006/\n",
      "üì∫ To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n",
      "üì∫ Opening a view to the Phoenix app. The app is running at http://127.0.0.1:6006/\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "session = px.launch_app()\n",
    "px.active_session().view()\n",
    "\n",
    "from phoenix.trace.langchain import OpenInferenceTracer, LangChainInstrumentor\n",
    "tracer = OpenInferenceTracer()\n",
    "LangChainInstrumentor(tracer).instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce450b-ae75-4c7e-b46c-85433d7a4c80",
   "metadata": {},
   "source": [
    "# Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5b0f76-620c-4671-99ed-a7a527b7b205",
   "metadata": {},
   "source": [
    "## Normal HTML reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aaab00b-5b61-404f-bde3-5ea5a3e56660",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004a7472-5d9f-4662-9732-18c6605d91e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|########################################################################################| 1/1 [00:00<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{},\n",
       " {'Header 2': 'Executive summary'},\n",
       " {'Header 2': 'Introduction'},\n",
       " {'Header 2': 'AI and geopolitics'},\n",
       " {'Header 2': 'The AI incumbents: The US & China'},\n",
       " {'Header 2': 'The AI capabilities of geopolitical swing states'},\n",
       " {'Header 2': 'The European Union'},\n",
       " {'Header 2': 'The United Kingdom'},\n",
       " {'Header 2': 'The United Arab Emirates'},\n",
       " {'Header 2': 'Israel'},\n",
       " {'Header 2': 'Japan, The Netherlands, South Korea, and Taiwan'},\n",
       " {'Header 2': 'India'},\n",
       " {'Header 2': 'The emerging AI powers'},\n",
       " {'Header 2': 'The geopolitics of AI governance'},\n",
       " {'Header 2': 'The emerging AI powers'},\n",
       " {'Header 2': 'How technological development drives geopolitics'},\n",
       " {'Header 2': 'The key debate: scale up or scale down?'},\n",
       " {'Header 2': 'The future of AI governance'},\n",
       " {'Header 2': 'Charting the chip wars'},\n",
       " {'Header 2': 'AI and commerce'},\n",
       " {'Header 2': 'Energy'},\n",
       " {'Header 2': 'Compute'},\n",
       " {'Header 2': 'Data'},\n",
       " {'Header 2': 'Models'},\n",
       " {'Header 2': 'What to watch'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_header_splits = load_and_split(**TEST_URLS[\"goldman\"])\n",
    "[h.metadata for h in html_header_splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fd39f-a3bd-4b35-a26c-abddb8e7fcd7",
   "metadata": {},
   "source": [
    "## Unstructured PDF reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7519e12e-06d1-408a-93e4-91a68f3d304d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import OnlinePDFLoader, UnstructuredPDFLoader\n",
    "\n",
    "loader = UnstructuredPDFLoader(\n",
    "    \"data_pdfs/tepco-tfcd-2023.pdf\",\n",
    "    # mode=\"elements\",\n",
    ")\n",
    "data = loader.load()\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")\n",
    "\n",
    "html_header_splits = text_splitter.split_documents(data)\n",
    "len(html_header_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a165148-4a86-4179-9f07-c0bf085a7138",
   "metadata": {},
   "source": [
    "## `llmsherpa` Layout PDF reader\n",
    "https://blog.llamaindex.ai/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "312125d9-4a0b-424c-a383-989398c02a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nlmatics/llmsherpa?tab=readme-ov-file#read-a-pdf-file\n",
    "from llmsherpa.readers import LayoutPDFReader\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "pdf_url = \"https://www.tepco.co.jp/en/hd/about/ir/library/integratedreport/pdf/2023TCFD-e.pdf\" # also allowed is a file path e.g. /home/downloads/xyz.pdf\n",
    "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
    "doc = pdf_reader.read_pdf(pdf_url)\n",
    "html_header_splits = [Document(page_content=chunk.to_context_text()) for chunk in doc.chunks()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6605f3-ec1d-43c1-abc6-d2932e240e0c",
   "metadata": {},
   "source": [
    "# Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c43e580-bb83-4d26-8a05-8a5e00f16e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import SKLearnVectorStore\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"WhereIsAI/UAE-Large-V1\")\n",
    "\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\", encode_kwargs=encode_kwargs)\n",
    "\n",
    "vector_store = SKLearnVectorStore.from_documents(html_header_splits, embeddings)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10cd2684-e19d-46e9-a9f6-8370469ffe0f",
   "metadata": {},
   "source": [
    "No sentence-transformers model found with name /Users/hide/.cache/torch/sentence_transformers/WhereIsAI_UAE-Large-V1. Creating a new one with MEAN pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "645805fc-18a6-41f2-9bd6-a17bfb4a88f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* `target` included\n",
      "* `co2` included\n",
      "* `emission` included\n",
      "* `reduction` included\n",
      "* `of` included\n",
      "* `power` included\n",
      "(Document(page_content='Metrics and Target : GHG Emission Reduction > Achieving CO2 reduction targets\\nThe TEPCO Group aims to reduce CO2 emissions originating from the sale of power by 50% of FY2013 levels by the year FY2030.', metadata={'id': '58486f19-1311-41e0-b1f6-fbb8db191ced'}), 0.8109984422679806)\n",
      "\n",
      "* `target` included\n",
      "* `reduction` included\n",
      "* `of` included\n",
      "* `power` included\n",
      "(Document(page_content='TEPCO Group At a Glance > Real GDP ÔºàFY2022) > Metrics and Targets > GHG Reduction Target\\nScope3 (the sale of power)', metadata={'id': 'e267b12e-3819-4123-8f41-28516345125e'}), 0.807420567403075)\n",
      "\n",
      "* `co2` included\n",
      "* `emission` included\n",
      "* `of` included\n",
      "* `power` included\n",
      "(Document(page_content='TEPCO Group At a Glance > Real GDP ÔºàFY2022) > Carbon Neutrality Strategies > Carbon neutrality declaration > Reduce CO2 emissions originating from the sale of power to 50% of FY2013 levels*\\nScope 1, 2 and 3 emissions are from the sale of power; Scope 1 and 2 emissions are compared to FY2019 levels', metadata={'id': 'be6de8fa-a965-48a1-9daf-002b256cb857'}), 0.7954588096558)\n",
      "\n",
      "* `target` included\n",
      "* `co2` included\n",
      "* `emission` included\n",
      "* `of` included\n",
      "* `power` included\n",
      "(Document(page_content='TEPCO Group At a Glance > NET ZERO > Metrics and Targets : Roadmap to Carbon Neutrality\\nIn light of the Paris Agreement, the TEPCO Group has set a goal of reducing CO2 emissions originating from the sale of power to 50% of FY2013 levels by 2030.\\nThe group also aims to reduce CO2 emissions originating from the supply of energy to net-zero by 2050 through achieving a ‚Äúbest mix‚Äù of power sources that considers both stable supply and economic feasibility, and innovation.', metadata={'id': '622cfb2e-d18c-49aa-bb68-bc85d326c4ae'}), 0.7824715547026944)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keywords = \"japan\".split(\" \")\n",
    "keywords = \"ÁõÆÊ®ô ÂâäÊ∏õ 50%\".split(\" \")\n",
    "keywords = \"target co2 emission reduction sales of power\".split(\" \")\n",
    "\n",
    "found_docs = vector_store.similarity_search_with_relevance_scores(\" \".join(keywords))\n",
    "\n",
    "for doc in found_docs:\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in doc[0].page_content.lower():\n",
    "            print(f\"* `{keyword}` included\")\n",
    "    print(doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501ba21-eb1b-4dee-9d0b-e714f2b1caeb",
   "metadata": {},
   "source": [
    "## POC for exact info extraction\n",
    "* Extracting Accurate Materials Data from Research Papers with Conversational Language Models and Prompt Engineering\n",
    "  * https://arxiv.org/abs/2303.05352\n",
    "* Need to update the prompt text for Llama2 Chat model\n",
    "  * add special chars?\n",
    "  * put the context before the question (like a chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e120ecbb-5aad-4ac8-941a-138d396e5eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama2:7b-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb889ec7-4ee2-4f2f-b406-48d9bf3654e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='This paper demonstrates that conversational LLMs such as ChatGPT, with proper prompt engineering and a series of follow-up questions, such as the ChatExtract approach presented here, are capable of providing high quality materials data extracted from research texts with no additional fine-tuning, extensive code development or deep knowledge about the property for which the data is extracted'\n",
      " No.\n",
      "---\n",
      "page_content='We present such a series of wellengineered prompts and follow-up questions in this paper and demonstrate its effectiveness resulting in a best performance of over 90% precision at 87.7% recall on our test set of bulk modulus data, and 91.6% precision and 83.6% on a full database of critical cooling rates'\n",
      " No\n",
      "---\n",
      "page_content='We show that the success of the ChatExtract method lies in asking follow-up questions with purposeful redundancy and introduction of uncertainty and information retention within the conversation by comparing to results when these aspects are removed'\n",
      " Yes.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_1st = PromptTemplate.from_template('''<s>[INST]\n",
    "---\n",
    "{doc}\n",
    "---\n",
    "\n",
    "There is a possibility that the data you extracted is incorrect.\n",
    "Answer \"Yes\" or \"No\" only. Be very strict. Is a full database of critical cooling rates the first compound for which the value of {property} is given the above text? Make sure it is a real compound.[/INST]\n",
    "''')\n",
    "\n",
    "chain = prompt_1st | llm\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "test_text = \"\"\"This paper demonstrates that conversational LLMs\n",
    "such as ChatGPT, with proper prompt engineering and\n",
    "a series of follow-up questions, such as the ChatExtract\n",
    "approach presented here, are capable of providing high\n",
    "quality materials data extracted from research texts with\n",
    "no additional fine-tuning, extensive code development\n",
    "or deep knowledge about the property for which the\n",
    "data is extracted. We present such a series of wellengineered prompts and follow-up questions in this paper and demonstrate its effectiveness resulting in a best\n",
    "performance of over 90% precision at 87.7% recall on\n",
    "our test set of bulk modulus data, and 91.6% precision\n",
    "and 83.6% on a full database of critical cooling rates.\n",
    "We show that the success of the ChatExtract method\n",
    "lies in asking follow-up questions with purposeful redundancy and introduction of uncertainty and information\n",
    "retention within the conversation by comparing to results when these aspects are removed. We further develop\n",
    "two databases using ChatExtract - a database of critical cooling rates for metallic glasses and yield strengths\n",
    "for high entropy alloys. The first one was modest-sized\n",
    "and served as a benchmark for full database development\n",
    "since we were able to compare it to data we extracted\n",
    "manually. The second one was a large database, to our\n",
    "knowledge the largest database of yield strength of high\n",
    "entropy alloys to date. The high quality of the extracted\n",
    "data and the simplicity of the approach suggests that\n",
    "approaches similar to ChatExtract offer an opportunity\n",
    "to replace previous, more labor intensive, methods. Since\n",
    "ChatExtract is largely independent of the used model, it\n",
    "is also likely improve by simply applying it to newer and\n",
    "more capable LLMs as they are developed in the future.\"\"\".replace('\\n', ' ')\n",
    "\n",
    "docs = [Document(page_content=sentence) for sentence in test_text.split('. ')]\n",
    "# print(docs)\n",
    "for doc in docs[:3]:\n",
    "    print(doc)\n",
    "    print(chain.invoke({\"property\": \"precision\", \"doc\": doc.page_content}))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daae9b5-cc51-4414-9d66-7fae1964b3e1",
   "metadata": {},
   "source": [
    "> sentence\n",
    "Answer \"Yes\" or \"No\" only. Does the above text contain a value of {property}?\n",
    "Answer \"Yes\" or \"No\" only. Does the above text contain more than one of {property}?\n",
    "\n",
    "> text\n",
    "Give the number only without units, do not use a full sentence. If the value is not present, type \"None\". What is the value of {property} in the above text?\n",
    "Give the unit only, do not use a full sentence. If the unit is not present, type \"None\". What is the unit of {property} in the above text?\n",
    "Give the material name only, do not use a full sentence. If the material name is not present, type \"None\". What is the material name of {property} in the above text?\n",
    "\n",
    "> multiple\n",
    "Use only data present in the text. If data is not present in the text, type \"None\". Summarize the value of the {property} in the above text in a form of table consisting of: Material, Value, Unit.\n",
    "There is a possibility that the data you extracted is incorrect. Answer \"Yes\" or \"No\" only. Be very strict. Is Bulk Modulus Data the first compound for which the value of {property} is given the above text? Make sure it is a real compound."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1b46b0-0afd-4029-8d92-85bb5a50bd06",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2d34baf-ca77-4be9-a1bc-1bf581de524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama2:7b-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3502309d-5306-4b07-9de8-fb02ec08f888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "check_template = \"\"\"<s>[INST]Please check if the following paragraph is related to Japan and rate this relevance to whether low, middle, or high.\n",
    "\n",
    "{docs}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "check_template = \"\"\"<s>[INST]Please extract the sentences exactly regardng Japan.\n",
    "\n",
    "{docs}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "check_prompt = PromptTemplate.from_template(check_template)\n",
    "check_chain = LLMChain(llm=llm, prompt=check_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c99ea049-7e4f-4d32-811b-4a0ff013b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(page_content='South Korea, Japan, and Taiwan are home to some of the world‚Äôs most important semiconductor design and manufacturing companies, as well as semiconductor manufacturing equipment makers. They are also located in critical geographies for global supply chains along the South China Sea and East China Sea. The world‚Äôs great powers are dependent on these countries for their own technological competitiveness.  \\nThe importance of these countries in multilateral cooperation has been clear for some time. In addition to their roles in the enforcement of export controls, in March 2022, US President Joe Biden reportedly proposed a ‚ÄúCHIP 4‚Äù grouping of the US and these three East Asian governments, a move seen as not only aimed at isolating Beijing, but also at creating greater supply-chain diversification and protecting companies‚Äô intellectual property. However, the initiative has not yet made significant progress.  \\nAs artificial intelligence becomes a greater part of daily life, these countries‚Äô geopolitical importance will continue to grow. Taiwan‚Äôs dominance of high-end semiconductor manufacturing is of particular consequence. The island nation manufactures 68% of semiconductors globally and 90% of leading-edge semiconductors necessary for advanced AI applications. No other country, and no other company, can produce high-end semiconductors in the quantity and quality of Taiwan Semiconductor Manufacturing Company (TSMC). The great powers rely on Taiwanese-made chips that power everything from smartphones to advanced weapons systems. Because of that reality, many leaders, including Taiwanese President Tsai Ing-wen, have referred to Taiwan‚Äôs semiconductor industry as its ‚Äúsilicon shield,‚Äù protecting it from aggression and supply-chain disruptions. However, a recent Council on Foreign Relations report argued that TSMC‚Äôs position may make potential aggression by Beijing more likely, as Beijing could have an interest in gaining control of the company and using it for geopolitical leverage.  \\nThe final country that is critical for global semiconductor supply chains is the Netherlands. The Dutch company ASML is the world‚Äôs only manufacturer of extreme ultraviolet lithography (EUV) machines, which are necessary for the ever-more sophisticated integrated circuits in semiconductor fabrication, at a cost of $330 million or more for each machine. According to Goldman Sachs Research, EUV could increase the size of the global semiconductor market from $600 billion in 2022 to $1 trillion by the end of the decade.', metadata={'id': '33486450-e039-42a5-8799-b39cd8ad02d2', 'Header 2': 'Japan, The Netherlands, South Korea, and Taiwan'}), 0.6755666676675587)\n",
      "---\n",
      "Sure, here are the sentences related to Japan:\n",
      "\n",
      "* South Korea, Japan, and Taiwan are home to some of the world's most important semiconductor design and manufacturing companies.\n",
      "* Japan is located in a critical geography for global supply chains along the South China Sea and East China Sea.\n",
      "* The great powers are dependent on these countries for their own technological competitiveness.\n",
      "\n",
      "In summary, Japan is mentioned as one of the countries home to important semiconductor companies and located in a critical geography for global supply chains.\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "for doc in found_docs[:1]:\n",
    "    print(doc)\n",
    "    print(\"---\")\n",
    "    print(check_chain.run(doc))\n",
    "    print(\"====\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
